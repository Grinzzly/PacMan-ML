{"dependencies":[{"name":"/home/szamulko/Desktop/Projects/PacMan/package.json","includedInParent":true,"mtime":1528724217926},{"name":"/home/szamulko/Desktop/Projects/PacMan/node_modules/@tensorflow/tfjs-core/package.json","includedInParent":true,"mtime":1528724212618},{"name":"../doc","loc":{"line":7,"column":20}},{"name":"../environment","loc":{"line":8,"column":20}},{"name":"../util","loc":{"line":9,"column":22}},{"name":"./operation","loc":{"line":10,"column":26}}],"generated":{"js":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n    value: true\n});\nexports.MatmulOps = undefined;\n\nvar _doc = require(\"../doc\");\n\nvar _environment = require(\"../environment\");\n\nvar _util = require(\"../util\");\n\nvar util = _interopRequireWildcard(_util);\n\nvar _operation = require(\"./operation\");\n\nfunction _interopRequireWildcard(obj) { if (obj && obj.__esModule) { return obj; } else { var newObj = {}; if (obj != null) { for (var key in obj) { if (Object.prototype.hasOwnProperty.call(obj, key)) newObj[key] = obj[key]; } } newObj.default = obj; return newObj; } }\n\nvar __decorate = undefined && undefined.__decorate || function (decorators, target, key, desc) {\n    var c = arguments.length,\n        r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc,\n        d;\n    if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n    return c > 3 && r && Object.defineProperty(target, key, r), r;\n};\n\nvar MatmulOps = function () {\n    function MatmulOps() {}\n    MatmulOps.matMul = function (a, b, transposeA, transposeB) {\n        if (transposeA === void 0) {\n            transposeA = false;\n        }\n        if (transposeB === void 0) {\n            transposeB = false;\n        }\n        util.assertArgumentsAreTensors({ a: a, b: b }, 'matMul');\n        var innerShapeA = transposeA ? a.shape[0] : a.shape[1];\n        var innerShapeB = transposeB ? b.shape[1] : b.shape[0];\n        util.assert(a.rank === 2 && b.rank === 2, \"Error in matMul: inputs must be rank 2, got ranks \" + a.rank + (\" and \" + b.rank + \".\"));\n        util.assert(innerShapeA === innerShapeB, \"Error in matMul: inner shapes (\" + innerShapeA + \") and (\" + (innerShapeB + \") of Tensors with shapes \" + a.shape + \" and \") + (b.shape + \" and transposeA=\" + transposeA) + (\" and transposeB=\" + transposeB + \" must match.\"));\n        var grad = function (dy) {\n            if (!transposeA && !transposeB) {\n                return {\n                    a: function () {\n                        return dy.matMul(b.toFloat(), false, true);\n                    },\n                    b: function () {\n                        return a.toFloat().matMul(dy, true, false);\n                    }\n                };\n            } else if (!transposeA && transposeB) {\n                return {\n                    a: function () {\n                        return dy.matMul(b.toFloat(), false, false);\n                    },\n                    b: function () {\n                        return dy.matMul(a.toFloat(), true, false);\n                    }\n                };\n            } else if (transposeA && !transposeB) {\n                return {\n                    a: function () {\n                        return b.toFloat().matMul(dy, false, true);\n                    },\n                    b: function () {\n                        return a.toFloat().matMul(dy, false, false);\n                    }\n                };\n            } else {\n                return {\n                    a: function () {\n                        return b.toFloat().matMul(dy, true, true);\n                    },\n                    b: function () {\n                        return dy.matMul(a.toFloat(), true, true);\n                    }\n                };\n            }\n        };\n        return _environment.ENV.engine.runKernel(function (backend) {\n            return backend.matMul(a, b, transposeA, transposeB);\n        }, { a: a, b: b }, grad);\n    };\n    MatmulOps.vectorTimesMatrix = function (v, matrix) {\n        util.assert(v.rank === 1, \"Error in vectorTimesMatrix: first input must be rank 1, but got \" + (\"rank \" + v.rank + \".\"));\n        util.assert(matrix.rank === 2, \"Error in vectorTimesMatrix: second input must be rank 2, but got \" + (\"rank \" + matrix.rank + \".\"));\n        util.assert(v.size === matrix.shape[0], \"Error in vectorTimesMatrix: size of vector (\" + v.size + \") \" + (\"must match first dimension of matrix (\" + matrix.shape[0] + \")\"));\n        return v.as2D(1, -1).matMul(matrix).as1D();\n    };\n    MatmulOps.matrixTimesVector = function (matrix, v) {\n        util.assert(v.rank === 1, \"Error in matrixTimesVector: second input must rank 1, but got \" + (\"rank \" + v.rank + \".\"));\n        util.assert(matrix.rank === 2, \"Error in matrixTimesVector: first input must be a rank 2, but got \" + (\"rank \" + matrix.rank + \".\"));\n        util.assert(v.size === matrix.shape[1], \"Error in matrixTimesVector: size of first rank 1 input \" + v.size + \" \" + \"must match inner dimension of second rank 2 input, but got \" + (\"shape \" + matrix.shape + \".\"));\n        return matrix.matMul(v.as2D(-1, 1)).as1D();\n    };\n    MatmulOps.dotProduct = function (v1, v2) {\n        util.assert(v1.rank === 1 && v2.rank === 1, \"Error in dotProduct: inputs must be rank 1, but got ranks \" + (v1.rank + \" and \" + v2.rank + \".\"));\n        util.assert(v1.size === v2.size, \"Error in dotProduct: size of inputs (\" + v1.size + \") and (\" + (v2.size + \") must match.\"));\n        return v1.as2D(1, -1).matMul(v2.as2D(-1, 1)).asScalar();\n    };\n    MatmulOps.outerProduct = function (v1, v2) {\n        util.assert(v1.rank === 1 && v2.rank === 1, \"Error in outerProduct: inputs must be rank 1, but got ranks \" + (v1.rank + \" and \" + v2.rank + \".\"));\n        return v1.as2D(-1, 1).matMul(v2.as2D(1, -1));\n    };\n    MatmulOps.dot = function (t1, t2) {\n        util.assert((t1.rank === 1 || t1.rank === 2) && (t2.rank === 1 || t2.rank === 2), \"Error in dot: inputs must all be rank 1 or 2, but got ranks \" + (t1.rank + \" and \" + t2.rank + \".\"));\n        var t1Inner = t1.rank === 1 ? t1.size : t1.shape[1];\n        var t2Inner = t2.rank === 1 ? t2.size : t2.shape[0];\n        util.assert(t1Inner === t2Inner, \"Error in dot: inner dimensions of inputs must match, but got \" + (t1Inner + \" and \" + t2Inner + \".\"));\n        if (t1.rank === 1 && t2.rank === 1) {\n            return t1.as2D(1, -1).matMul(t2.as2D(-1, 1)).asScalar();\n        } else if (t1.rank === 1 && t2.rank === 2) {\n            return t1.as2D(1, -1).matMul(t2.as2D(t2.shape[0], t2.shape[1])).as1D();\n        } else if (t1.rank === 2 && t2.rank === 1) {\n            return t1.matMul(t2.as2D(-1, 1)).as1D();\n        } else {\n            return t1.matMul(t2.as2D(t2.shape[0], t2.shape[1]));\n        }\n    };\n    __decorate([(0, _doc.doc)({ heading: 'Operations', subheading: 'Matrices' }), _operation.operation], MatmulOps, \"matMul\", null);\n    __decorate([_operation.operation], MatmulOps, \"vectorTimesMatrix\", null);\n    __decorate([_operation.operation], MatmulOps, \"matrixTimesVector\", null);\n    __decorate([_operation.operation], MatmulOps, \"dotProduct\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Operations', subheading: 'Matrices' }), _operation.operation], MatmulOps, \"outerProduct\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Operations', subheading: 'Matrices' }), _operation.operation], MatmulOps, \"dot\", null);\n    return MatmulOps;\n}();\nexports.MatmulOps = MatmulOps;\n//# sourceMappingURL=matmul.js.map"},"hash":"40928767239d19412c94e2fe89edd7f0","cacheData":{"env":{}}}
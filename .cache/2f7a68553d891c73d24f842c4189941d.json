{"dependencies":[{"name":"/home/szamulko/Desktop/Projects/PacMan/package.json","includedInParent":true,"mtime":1528724217926},{"name":"/home/szamulko/Desktop/Projects/PacMan/node_modules/@tensorflow/tfjs-layers/package.json","includedInParent":true,"mtime":1528724212618},{"name":"@tensorflow/tfjs-core","loc":{"line":2,"column":29}},{"name":"./backend/tfjs_backend","loc":{"line":3,"column":19}},{"name":"./errors","loc":{"line":4,"column":27}}],"generated":{"js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n    value: true\n});\nexports.cosine = exports.KLD = exports.kld = exports.MSLE = exports.msle = exports.MAPE = exports.mape = exports.MAE = exports.mae = exports.MSE = exports.mse = undefined;\nexports.l2Normalize = l2Normalize;\nexports.meanSquaredError = meanSquaredError;\nexports.meanAbsoluteError = meanAbsoluteError;\nexports.meanAbsolutePercentageError = meanAbsolutePercentageError;\nexports.meanSquaredLogarithmicError = meanSquaredLogarithmicError;\nexports.squaredHinge = squaredHinge;\nexports.hinge = hinge;\nexports.categoricalHinge = categoricalHinge;\nexports.logcosh = logcosh;\nexports.categoricalCrossentropy = categoricalCrossentropy;\nexports.sparseCategoricalCrossentropy = sparseCategoricalCrossentropy;\nexports.sigmoidCrossEntropyWithLogits = sigmoidCrossEntropyWithLogits;\nexports.binaryCrossentropy = binaryCrossentropy;\nexports.kullbackLeiblerDivergence = kullbackLeiblerDivergence;\nexports.poisson = poisson;\nexports.cosineProximity = cosineProximity;\nexports.get = get;\n\nvar _tfjsCore = require('@tensorflow/tfjs-core');\n\nvar tfc = _interopRequireWildcard(_tfjsCore);\n\nvar _tfjs_backend = require('./backend/tfjs_backend');\n\nvar K = _interopRequireWildcard(_tfjs_backend);\n\nvar _errors = require('./errors');\n\nfunction _interopRequireWildcard(obj) { if (obj && obj.__esModule) { return obj; } else { var newObj = {}; if (obj != null) { for (var key in obj) { if (Object.prototype.hasOwnProperty.call(obj, key)) newObj[key] = obj[key]; } } newObj.default = obj; return newObj; } }\n\nfunction l2Normalize(x, axis) {\n    return (0, _tfjsCore.tidy)(function () {\n        var squareSum = tfc.sum(K.square(x), axis, true);\n        var epsilonTensor = K.scalarTimesArray((0, _tfjsCore.scalar)(K.epsilon()), tfc.onesLike(x));\n        var norm = tfc.sqrt(tfc.maximum(squareSum, epsilonTensor));\n        return tfc.div(x, norm);\n    });\n}\nfunction meanSquaredError(yTrue, yPred) {\n    return (0, _tfjsCore.tidy)(function () {\n        return tfc.mean(K.square(tfc.sub(yPred, yTrue)), -1);\n    });\n}\nfunction meanAbsoluteError(yTrue, yPred) {\n    return (0, _tfjsCore.tidy)(function () {\n        return tfc.mean(tfc.abs(tfc.sub(yPred, yTrue)), -1);\n    });\n}\nfunction meanAbsolutePercentageError(yTrue, yPred) {\n    return (0, _tfjsCore.tidy)(function () {\n        var diff = tfc.sub(yTrue, yPred);\n        var clippedTrue = tfc.clipByValue(tfc.abs(yTrue), K.epsilon(), Number.MAX_VALUE);\n        var absResult = tfc.abs(tfc.div(diff, clippedTrue));\n        return K.scalarTimesArray(K.getScalar(100.0), tfc.mean(absResult, -1));\n    });\n}\nfunction meanSquaredLogarithmicError(yTrue, yPred) {\n    return (0, _tfjsCore.tidy)(function () {\n        var one = K.getScalar(1.0);\n        var clippedPred = tfc.clipByValue(yPred, K.epsilon(), Number.MAX_VALUE);\n        var firstLog = tfc.log(K.scalarPlusArray(one, clippedPred));\n        var clippedTrue = tfc.clipByValue(yTrue, K.epsilon(), Number.MAX_VALUE);\n        var secondLog = tfc.log(K.scalarPlusArray(one, clippedTrue));\n        return tfc.mean(K.square(tfc.sub(firstLog, secondLog)), -1);\n    });\n}\nfunction squaredHinge(yTrue, yPred) {\n    return (0, _tfjsCore.tidy)(function () {\n        var zeroTensor = K.getScalar(0.0);\n        var one = K.getScalar(1.0);\n        var maxResult = tfc.maximum(zeroTensor, tfc.sub(one, tfc.mul(yTrue, yPred)));\n        return tfc.mean(K.square(maxResult), -1);\n    });\n}\nfunction hinge(yTrue, yPred) {\n    return (0, _tfjsCore.tidy)(function () {\n        var zeroTensor = K.getScalar(0.0);\n        var one = K.getScalar(1.0);\n        var maxResult = tfc.maximum(zeroTensor, tfc.sub(one, tfc.mul(yTrue, yPred)));\n        return tfc.mean(maxResult, -1);\n    });\n}\nfunction categoricalHinge(yTrue, yPred) {\n    return (0, _tfjsCore.tidy)(function () {\n        var zeroTensor = K.getScalar(0.0);\n        var one = K.getScalar(1.0);\n        var pos = tfc.sum(tfc.mul(yTrue, yPred), -1);\n        var neg = tfc.max(tfc.mul(tfc.sub(one, yTrue), yPred), -1);\n        return tfc.maximum(zeroTensor, K.scalarPlusArray(one, tfc.sub(neg, pos)));\n    });\n}\nfunction logcosh(yTrue, yPred) {\n    return (0, _tfjsCore.tidy)(function () {\n        var log2 = K.getScalar(Math.log(2.0));\n        var predictionDiff = tfc.sub(yPred, yTrue);\n        var logcoshResult = tfc.sub(tfc.add(predictionDiff, tfc.softplus(K.scalarTimesArray(K.getScalar(-2.0), predictionDiff))), log2);\n        return tfc.mean(logcoshResult, -1);\n    });\n}\nfunction categoricalCrossentropy(target, output, fromLogits) {\n    if (fromLogits === void 0) {\n        fromLogits = false;\n    }\n    return (0, _tfjsCore.tidy)(function () {\n        if (fromLogits) {\n            output = tfc.softmax(output);\n        } else {\n            var outputSum = tfc.sum(output, K.shape(output).length - 1, true);\n            output = tfc.div(output, outputSum);\n        }\n        output = tfc.clipByValue(output, K.epsilon(), 1 - K.epsilon());\n        return tfc.neg(tfc.sum(tfc.mul(target.toFloat(), tfc.log(output)), K.shape(output).length - 1));\n    });\n}\nfunction sparseCategoricalCrossentropy(target, output, fromLogits) {\n    if (fromLogits === void 0) {\n        fromLogits = false;\n    }\n    return (0, _tfjsCore.tidy)(function () {\n        var flatTarget = tfc.floor(K.flatten(target)).toInt();\n        var outputShape = K.shape(output);\n        var oneHotTarget = tfc.oneHot(flatTarget, outputShape[outputShape.length - 1]).reshape(outputShape);\n        return categoricalCrossentropy(oneHotTarget, output, fromLogits);\n    });\n}\nfunction sigmoidCrossEntropyWithLogits(target, output) {\n    return (0, _tfjsCore.tidy)(function () {\n        var maxOutput = tfc.maximum(output, tfc.zerosLike(output));\n        var outputXTarget = tfc.mul(output, target);\n        var sigmoidOutput = tfc.log(tfc.add(K.getScalar(1), tfc.exp(tfc.neg(tfc.abs(output)))));\n        var result = tfc.add(tfc.sub(maxOutput, outputXTarget), sigmoidOutput);\n        return result;\n    });\n}\nfunction binaryCrossentropy(yTrue, yPred) {\n    return (0, _tfjsCore.tidy)(function () {\n        var y;\n        y = tfc.clipByValue(yPred, K.epsilon(), 1 - K.epsilon());\n        y = tfc.log(tfc.div(y, tfc.sub(tfc.onesLike(y), y)));\n        return tfc.mean(sigmoidCrossEntropyWithLogits(yTrue, y), -1);\n    });\n}\nfunction kullbackLeiblerDivergence(yTrue, yPred) {\n    return (0, _tfjsCore.tidy)(function () {\n        var clippedTrue = tfc.clipByValue(yTrue, K.epsilon(), 1);\n        var clippedPred = tfc.clipByValue(yPred, K.epsilon(), 1);\n        return tfc.sum(tfc.mul(yTrue, tfc.log(tfc.div(clippedTrue, clippedPred))), -1);\n    });\n}\nfunction poisson(yTrue, yPred) {\n    return (0, _tfjsCore.tidy)(function () {\n        var logPred = tfc.log(K.scalarPlusArray(K.getScalar(K.epsilon()), yPred));\n        return tfc.mean(tfc.sub(yPred, tfc.mul(yTrue, logPred)), -1);\n    });\n}\nfunction cosineProximity(yTrue, yPred) {\n    return (0, _tfjsCore.tidy)(function () {\n        var trueNormalized = l2Normalize(yTrue, -1);\n        var predNormalized = l2Normalize(yPred, -1);\n        var trueXPred = tfc.mul(trueNormalized, predNormalized);\n        return tfc.neg(tfc.sum(trueXPred, -1));\n    });\n}\nvar mse = exports.mse = meanSquaredError;\nvar MSE = exports.MSE = meanSquaredError;\nvar mae = exports.mae = meanAbsoluteError;\nvar MAE = exports.MAE = meanAbsoluteError;\nvar mape = exports.mape = meanAbsolutePercentageError;\nvar MAPE = exports.MAPE = meanAbsolutePercentageError;\nvar msle = exports.msle = meanSquaredLogarithmicError;\nvar MSLE = exports.MSLE = meanSquaredLogarithmicError;\nvar kld = exports.kld = kullbackLeiblerDivergence;\nvar KLD = exports.KLD = kullbackLeiblerDivergence;\nvar cosine = exports.cosine = cosineProximity;\nfunction get(identifierOrFn) {\n    var lossesMap = {\n        meanSquaredError: meanSquaredError,\n        meanAbsoluteError: meanAbsoluteError,\n        meanAbsolutePercentageError: meanAbsolutePercentageError,\n        meanSquaredLogarithmicError: meanSquaredLogarithmicError,\n        squaredHinge: squaredHinge,\n        hinge: hinge,\n        categoricalHinge: categoricalHinge,\n        logcosh: logcosh,\n        categoricalCrossentropy: categoricalCrossentropy,\n        sparseCategoricalCrossentropy: sparseCategoricalCrossentropy,\n        binaryCrossentropy: binaryCrossentropy,\n        kullbackLeiblerDivergence: kullbackLeiblerDivergence,\n        poisson: poisson,\n        cosineProximity: cosineProximity\n    };\n    if (typeof identifierOrFn === 'string') {\n        if (identifierOrFn in lossesMap) {\n            return lossesMap[identifierOrFn];\n        }\n        throw new _errors.ValueError(\"Unknown loss \" + identifierOrFn);\n    } else {\n        return identifierOrFn;\n    }\n}\n//# sourceMappingURL=losses.js.map"},"hash":"d059c62481b040338a3f4d37e9bd2353","cacheData":{"env":{}}}
{"dependencies":[{"name":"/home/szamulko/Desktop/Projects/PacMan/package.json","includedInParent":true,"mtime":1528724217926},{"name":"/home/szamulko/Desktop/Projects/PacMan/node_modules/@tensorflow/tfjs-core/package.json","includedInParent":true,"mtime":1528724212618},{"name":"../doc","loc":{"line":42,"column":20}},{"name":"../environment","loc":{"line":43,"column":20}},{"name":"../tensor","loc":{"line":44,"column":37}},{"name":"../tensor_util","loc":{"line":45,"column":29}},{"name":"../util","loc":{"line":46,"column":22}},{"name":"./axis_util","loc":{"line":47,"column":69}},{"name":"./concat","loc":{"line":48,"column":26}},{"name":"./operation","loc":{"line":49,"column":26}},{"name":"./rand","loc":{"line":50,"column":28}},{"name":"./reduction_ops","loc":{"line":51,"column":29}}],"generated":{"js":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n    value: true\n});\nexports.ArrayOps = undefined;\n\nvar _doc = require(\"../doc\");\n\nvar _environment = require(\"../environment\");\n\nvar _tensor = require(\"../tensor\");\n\nvar _tensor_util = require(\"../tensor_util\");\n\nvar tensor_util = _interopRequireWildcard(_tensor_util);\n\nvar _util = require(\"../util\");\n\nvar util = _interopRequireWildcard(_util);\n\nvar _axis_util = require(\"./axis_util\");\n\nvar _concat = require(\"./concat\");\n\nvar _operation = require(\"./operation\");\n\nvar _rand = require(\"./rand\");\n\nvar _reduction_ops = require(\"./reduction_ops\");\n\nfunction _interopRequireWildcard(obj) { if (obj && obj.__esModule) { return obj; } else { var newObj = {}; if (obj != null) { for (var key in obj) { if (Object.prototype.hasOwnProperty.call(obj, key)) newObj[key] = obj[key]; } } newObj.default = obj; return newObj; } }\n\nvar __decorate = undefined && undefined.__decorate || function (decorators, target, key, desc) {\n    var c = arguments.length,\n        r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc,\n        d;\n    if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n    return c > 3 && r && Object.defineProperty(target, key, r), r;\n};\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) {\n            try {\n                step(generator.next(value));\n            } catch (e) {\n                reject(e);\n            }\n        }\n        function rejected(value) {\n            try {\n                step(generator[\"throw\"](value));\n            } catch (e) {\n                reject(e);\n            }\n        }\n        function step(result) {\n            result.done ? resolve(result.value) : new P(function (resolve) {\n                resolve(result.value);\n            }).then(fulfilled, rejected);\n        }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = undefined && undefined.__generator || function (thisArg, body) {\n    var _ = { label: 0, sent: function () {\n            if (t[0] & 1) throw t[1];return t[1];\n        }, trys: [], ops: [] },\n        f,\n        y,\n        t,\n        g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function () {\n        return this;\n    }), g;\n    function verb(n) {\n        return function (v) {\n            return step([n, v]);\n        };\n    }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = y[op[0] & 2 ? \"return\" : op[0] ? \"throw\" : \"next\"]) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [0, t.value];\n            switch (op[0]) {\n                case 0:case 1:\n                    t = op;break;\n                case 4:\n                    _.label++;return { value: op[1], done: false };\n                case 5:\n                    _.label++;y = op[1];op = [0];continue;\n                case 7:\n                    op = _.ops.pop();_.trys.pop();continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) {\n                        _ = 0;continue;\n                    }\n                    if (op[0] === 3 && (!t || op[1] > t[0] && op[1] < t[3])) {\n                        _.label = op[1];break;\n                    }\n                    if (op[0] === 6 && _.label < t[1]) {\n                        _.label = t[1];t = op;break;\n                    }\n                    if (t && _.label < t[2]) {\n                        _.label = t[2];_.ops.push(op);break;\n                    }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop();continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) {\n            op = [6, e];y = 0;\n        } finally {\n            f = t = 0;\n        }\n        if (op[0] & 5) throw op[1];return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\n\nvar ArrayOps = function () {\n    function ArrayOps() {}\n    ArrayOps.tensor = function (values, shape, dtype) {\n        if (dtype === void 0) {\n            dtype = 'float32';\n        }\n        var inferredShape = util.inferShape(values);\n        if (shape != null && inferredShape.length !== 1) {\n            util.assertShapesMatch(shape, inferredShape, \"Error creating a new Tensor. \" + (\"Inferred shape (\" + inferredShape + \") does not match the \") + (\"provided shape (\" + shape + \"). \"));\n        }\n        if (!util.isTypedArray(values) && !Array.isArray(values)) {\n            values = [values];\n        }\n        shape = shape || inferredShape;\n        return _tensor.Tensor.make(shape, { values: toTypedArray(values, dtype) }, dtype);\n    };\n    ArrayOps.scalar = function (value, dtype) {\n        if (dtype === void 0) {\n            dtype = 'float32';\n        }\n        if (util.isTypedArray(value) || Array.isArray(value)) {\n            throw new Error('Error creating a new Scalar: value must be a primitive ' + '(number|boolean)');\n        }\n        return ArrayOps.tensor(value, [], dtype);\n    };\n    ArrayOps.tensor1d = function (values, dtype) {\n        if (dtype === void 0) {\n            dtype = 'float32';\n        }\n        var inferredShape = util.inferShape(values);\n        if (inferredShape.length !== 1) {\n            throw new Error('tensor1d() requires values to be a flat/TypedArray');\n        }\n        return ArrayOps.tensor(values, inferredShape, dtype);\n    };\n    ArrayOps.tensor2d = function (values, shape, dtype) {\n        if (dtype === void 0) {\n            dtype = 'float32';\n        }\n        if (shape != null && shape.length !== 2) {\n            throw new Error('tensor2d() requires shape to have two numbers');\n        }\n        var inferredShape = util.inferShape(values);\n        if (inferredShape.length !== 2 && inferredShape.length !== 1) {\n            throw new Error('tensor2d() requires values to be number[][] or flat/TypedArray');\n        }\n        if (inferredShape.length === 1 && shape == null) {\n            throw new Error('tensor2d() requires shape to be provided when `values` ' + 'are a flat/TypedArray');\n        }\n        shape = shape || inferredShape;\n        return ArrayOps.tensor(values, shape, dtype);\n    };\n    ArrayOps.tensor3d = function (values, shape, dtype) {\n        if (dtype === void 0) {\n            dtype = 'float32';\n        }\n        if (shape != null && shape.length !== 3) {\n            throw new Error('tensor3d() requires shape to have three numbers');\n        }\n        var inferredShape = util.inferShape(values);\n        if (inferredShape.length !== 3 && inferredShape.length !== 1) {\n            throw new Error('tensor3d() requires values to be number[][][] or flat/TypedArray');\n        }\n        if (inferredShape.length === 1 && shape == null) {\n            throw new Error('tensor3d() requires shape to be provided when `values` ' + 'are a flat array');\n        }\n        shape = shape || inferredShape;\n        return ArrayOps.tensor(values, shape, dtype);\n    };\n    ArrayOps.tensor4d = function (values, shape, dtype) {\n        if (dtype === void 0) {\n            dtype = 'float32';\n        }\n        if (shape != null && shape.length !== 4) {\n            throw new Error('tensor4d() requires shape to have four numbers');\n        }\n        var inferredShape = util.inferShape(values);\n        if (inferredShape.length !== 4 && inferredShape.length !== 1) {\n            throw new Error('tensor4d() requires values to be number[][][][] or flat/TypedArray');\n        }\n        if (inferredShape.length === 1 && shape == null) {\n            throw new Error('tensor4d() requires shape to be provided when `values` ' + 'are a flat array');\n        }\n        shape = shape || inferredShape;\n        return ArrayOps.tensor(values, shape, dtype);\n    };\n    ArrayOps.tensor5d = function (values, shape, dtype) {\n        if (dtype === void 0) {\n            dtype = 'float32';\n        }\n        if (shape != null && shape.length !== 5) {\n            throw new Error('tensor5d() requires shape to have five numbers');\n        }\n        var inferredShape = util.inferShape(values);\n        if (inferredShape.length !== 5 && inferredShape.length !== 1) {\n            throw new Error('tensor5d() requires values to be \\\n           number[][][][][] or flat/TypedArray');\n        }\n        if (inferredShape.length === 1 && shape == null) {\n            throw new Error('tensor5d() requires shape to be provided when `values` ' + 'are a flat array');\n        }\n        shape = shape || inferredShape;\n        return ArrayOps.tensor(values, shape, dtype);\n    };\n    ArrayOps.ones = function (shape, dtype) {\n        if (dtype === void 0) {\n            dtype = 'float32';\n        }\n        var values = makeOnesTypedArray(util.sizeFromShape(shape), dtype);\n        return _tensor.Tensor.make(shape, { values: values }, dtype);\n    };\n    ArrayOps.zeros = function (shape, dtype) {\n        if (dtype === void 0) {\n            dtype = 'float32';\n        }\n        var values = makeZerosTypedArray(util.sizeFromShape(shape), dtype);\n        return _tensor.Tensor.make(shape, { values: values }, dtype);\n    };\n    ArrayOps.fill = function (shape, value, dtype) {\n        if (dtype === void 0) {\n            dtype = 'float32';\n        }\n        var values = util.getTypedArrayFromDType(dtype, util.sizeFromShape(shape));\n        values.fill(value);\n        return _tensor.Tensor.make(shape, { values: values }, dtype);\n    };\n    ArrayOps.onesLike = function (x) {\n        util.assertArgumentsAreTensors({ x: x }, 'onesLike');\n        return ArrayOps.ones(x.shape, x.dtype);\n    };\n    ArrayOps.zerosLike = function (x) {\n        util.assertArgumentsAreTensors({ x: x }, 'zerosLike');\n        return ArrayOps.zeros(x.shape, x.dtype);\n    };\n    ArrayOps.clone = function (x) {\n        util.assertArgumentsAreTensors({ x: x }, 'clone');\n        var der = function (dy) {\n            return { x: function () {\n                    return dy.toFloat();\n                } };\n        };\n        return _environment.ENV.engine.runKernel(function (backend) {\n            return _tensor.Tensor.make(x.shape, { dataId: x.dataId }, x.dtype);\n        }, { x: x }, der);\n    };\n    ArrayOps.eye = function (numRows, numColumns, batchShape, dtype) {\n        if (dtype === void 0) {\n            dtype = 'float32';\n        }\n        if (numColumns == null) {\n            numColumns = numRows;\n        }\n        var buffer = ArrayOps.buffer([numRows, numColumns], dtype);\n        var n = numRows <= numColumns ? numRows : numColumns;\n        for (var i = 0; i < n; ++i) {\n            buffer.set(1, i, i);\n        }\n        var out = buffer.toTensor().as2D(numRows, numColumns);\n        if (batchShape == null) {\n            return out;\n        } else {\n            if (batchShape.length === 1) {\n                return ArrayOps.tile(ArrayOps.expandDims(out, 0), [batchShape[0], 1, 1]);\n            } else if (batchShape.length === 2) {\n                return ArrayOps.tile(ArrayOps.expandDims(ArrayOps.expandDims(out, 0), 0), [batchShape[0], batchShape[1], 1, 1]);\n            } else {\n                throw new Error(\"eye() currently supports only 1D and 2D \" + (\"batchShapes, but received \" + batchShape.length + \"D.\"));\n            }\n        }\n    };\n    ArrayOps.randomNormal = function (shape, mean, stdDev, dtype, seed) {\n        if (mean === void 0) {\n            mean = 0;\n        }\n        if (stdDev === void 0) {\n            stdDev = 1;\n        }\n        if (dtype != null && dtype === 'bool') {\n            throw new Error(\"Unsupported data type \" + dtype);\n        }\n        var randGauss = new _rand.MPRandGauss(mean, stdDev, dtype, false, seed);\n        var res = ArrayOps.buffer(shape, dtype);\n        for (var i = 0; i < res.values.length; i++) {\n            res.values[i] = randGauss.nextValue();\n        }\n        return res.toTensor();\n    };\n    ArrayOps.truncatedNormal = function (shape, mean, stdDev, dtype, seed) {\n        if (mean === void 0) {\n            mean = 0;\n        }\n        if (stdDev === void 0) {\n            stdDev = 1;\n        }\n        if (dtype != null && dtype === 'bool') {\n            throw new Error(\"Unsupported data type \" + dtype);\n        }\n        var randGauss = new _rand.MPRandGauss(mean, stdDev, dtype, true, seed);\n        var res = ArrayOps.buffer(shape, dtype);\n        for (var i = 0; i < res.values.length; i++) {\n            res.values[i] = randGauss.nextValue();\n        }\n        return res.toTensor();\n    };\n    ArrayOps.randomUniform = function (shape, minval, maxval, dtype) {\n        if (minval === void 0) {\n            minval = 0;\n        }\n        if (maxval === void 0) {\n            maxval = 1;\n        }\n        if (dtype === void 0) {\n            dtype = 'float32';\n        }\n        var res = ArrayOps.buffer(shape, dtype);\n        for (var i = 0; i < res.values.length; i++) {\n            res.values[i] = util.randUniform(minval, maxval);\n        }\n        return res.toTensor();\n    };\n    ArrayOps.rand = function (shape, randFunction, dtype) {\n        var size = util.sizeFromShape(shape);\n        var values = null;\n        if (dtype == null || dtype === 'float32') {\n            values = new Float32Array(size);\n        } else if (dtype === 'int32') {\n            values = new Int32Array(size);\n        } else if (dtype === 'bool') {\n            values = new Uint8Array(size);\n        } else {\n            throw new Error(\"Unknown data type \" + dtype);\n        }\n        for (var i = 0; i < size; i++) {\n            values[i] = randFunction();\n        }\n        return _tensor.Tensor.make(shape, { values: values }, dtype);\n    };\n    ArrayOps.multinomial = function (logits, numSamples, seed, normalized) {\n        if (normalized === void 0) {\n            normalized = false;\n        }\n        util.assertArgumentsAreTensors({ logits: logits }, 'multinomial');\n        var numOutcomes = logits.size;\n        var origRank = logits.rank;\n        if (numOutcomes < 2) {\n            throw new Error(\"Error in multinomial: you need at least 2 outcomes, but got \" + (numOutcomes + \".\"));\n        }\n        if (origRank > 2) {\n            throw new Error(\"Rank of probabilities must be 1 or 2, but is \" + origRank);\n        }\n        seed = seed || Math.random();\n        var logits2D = origRank === 1 ? logits.as2D(1, -1) : logits;\n        var res = _environment.ENV.engine.runKernel(function (backend) {\n            return backend.multinomial(logits2D, normalized, numSamples, seed);\n        }, { logits2D: logits2D });\n        return origRank === 1 ? res.as1D() : res;\n    };\n    ArrayOps.oneHot = function (indices, depth, onValue, offValue) {\n        if (onValue === void 0) {\n            onValue = 1;\n        }\n        if (offValue === void 0) {\n            offValue = 0;\n        }\n        util.assert(indices.dtype === 'int32', 'Indices must be of dtype `int32`');\n        if (depth < 2) {\n            throw new Error(\"Error in oneHot: depth must be >=2, but it is \" + depth);\n        }\n        return _environment.ENV.engine.runKernel(function (backend) {\n            return backend.oneHot(indices, depth, onValue, offValue);\n        }, { indices: indices });\n    };\n    ArrayOps.fromPixels = function (pixels, numChannels) {\n        if (numChannels === void 0) {\n            numChannels = 3;\n        }\n        if (numChannels > 4) {\n            throw new Error('Cannot construct Tensor with more than 4 channels from pixels.');\n        }\n        return _environment.ENV.engine.fromPixels(pixels, numChannels);\n    };\n    ArrayOps.toPixels = function (img, canvas) {\n        return __awaiter(this, void 0, void 0, function () {\n            var _a, height, width, depth, minTensor, maxTensor, min, max, data, multiplier, bytes, i, r, g, b, a, j, ctx, imageData;\n            return __generator(this, function (_b) {\n                switch (_b.label) {\n                    case 0:\n                        util.assertArgumentsAreTensors({ img: img }, 'toPixels');\n                        if (img.rank !== 2 && img.rank !== 3) {\n                            throw new Error(\"toPixels only supports rank 2 or 3 tensors, got rank \" + img.rank + \".\");\n                        }\n                        _a = img.shape.slice(0, 2), height = _a[0], width = _a[1];\n                        depth = img.rank === 2 ? 1 : img.shape[2];\n                        if (depth > 4 || depth === 2) {\n                            throw new Error(\"toPixels only supports depth of size \" + (\"1, 3 or 4 but got \" + depth));\n                        }\n                        minTensor = img.min();\n                        maxTensor = img.max();\n                        return [4, minTensor.data()];\n                    case 1:\n                        min = _b.sent()[0];\n                        return [4, maxTensor.data()];\n                    case 2:\n                        max = _b.sent()[0];\n                        minTensor.dispose();\n                        maxTensor.dispose();\n                        if (img.dtype === 'float32') {\n                            if (min < 0 || max > 1) {\n                                throw new Error(\"Tensor values for a float32 Tensor must be in the \" + (\"range [0 - 1] but got range [\" + min + \" - \" + max + \"].\"));\n                            }\n                        } else if (img.dtype === 'int32') {\n                            if (min < 0 || max > 255) {\n                                throw new Error(\"Tensor values for a int32 Tensor must be in the \" + (\"range [0 - 255] but got range [\" + min + \" - \" + max + \"].\"));\n                            }\n                        } else {\n                            throw new Error(\"Unsupported type for toPixels: \" + img.dtype + \".\" + \" Please use float32 or int32 tensors.\");\n                        }\n                        return [4, img.data()];\n                    case 3:\n                        data = _b.sent();\n                        multiplier = img.dtype === 'float32' ? 255 : 1;\n                        bytes = new Uint8ClampedArray(width * height * 4);\n                        for (i = 0; i < height * width; ++i) {\n                            r = void 0, g = void 0, b = void 0, a = void 0;\n                            if (depth === 1) {\n                                r = data[i] * multiplier;\n                                g = data[i] * multiplier;\n                                b = data[i] * multiplier;\n                                a = 255;\n                            } else if (depth === 3) {\n                                r = data[i * 3] * multiplier;\n                                g = data[i * 3 + 1] * multiplier;\n                                b = data[i * 3 + 2] * multiplier;\n                                a = 255;\n                            } else if (depth === 4) {\n                                r = data[i * 4] * multiplier;\n                                g = data[i * 4 + 1] * multiplier;\n                                b = data[i * 4 + 2] * multiplier;\n                                a = data[i * 4 + 3] * multiplier;\n                            }\n                            j = i * 4;\n                            bytes[j + 0] = Math.round(r);\n                            bytes[j + 1] = Math.round(g);\n                            bytes[j + 2] = Math.round(b);\n                            bytes[j + 3] = Math.round(a);\n                        }\n                        if (canvas != null) {\n                            canvas.width = width;\n                            canvas.height = height;\n                            ctx = canvas.getContext('2d');\n                            imageData = new ImageData(bytes, width, height);\n                            ctx.putImageData(imageData, 0, 0);\n                        }\n                        return [2, bytes];\n                }\n            });\n        });\n    };\n    ArrayOps.reshape = function (x, shape) {\n        util.assertArgumentsAreTensors({ x: x }, 'reshape');\n        shape = util.inferFromImplicitShape(shape, x.size);\n        util.assert(x.size === util.sizeFromShape(shape), 'new shape and old shape must have the same number of elements.');\n        var grad = function (dy) {\n            return { x: function () {\n                    return dy.reshape(x.shape);\n                } };\n        };\n        return _environment.ENV.engine.runKernel(function (backend) {\n            return backend.reshape(x, shape);\n        }, { x: x }, grad);\n    };\n    ArrayOps.squeeze = function (x, axis) {\n        util.assertArgumentsAreTensors({ x: x }, 'squeeze');\n        return ArrayOps.reshape(x, util.squeezeShape(x.shape, axis).newShape);\n    };\n    ArrayOps.cast = function (x, dtype) {\n        util.assertArgumentsAreTensors({ x: x }, 'cast');\n        var grad = function (dy) {\n            return { x: function () {\n                    return dy.clone();\n                } };\n        };\n        return _environment.ENV.engine.runKernel(function (backend) {\n            return backend.cast(x, dtype);\n        }, { x: x }, grad);\n    };\n    ArrayOps.tile = function (x, reps) {\n        util.assertArgumentsAreTensors({ x: x }, 'tile');\n        util.assert(x.rank === reps.length, \"Error in transpose: rank of input \" + x.rank + \" \" + (\"must match length of reps \" + reps + \".\"));\n        var grad = function (dy) {\n            var derX = function () {\n                var xGrad = ArrayOps.zerosLike(x);\n                if (x.rank === 1) {\n                    for (var i = 0; i < reps[0]; ++i) {\n                        xGrad = xGrad.add(dy.slice([i * x.shape[0]], [x.shape[0]]));\n                    }\n                } else if (x.rank === 2) {\n                    for (var i = 0; i < reps[0]; ++i) {\n                        for (var j = 0; j < reps[1]; ++j) {\n                            xGrad = xGrad.add(dy.slice([i * x.shape[0], j * x.shape[1]], [x.shape[0], x.shape[1]]));\n                        }\n                    }\n                } else if (x.rank === 3) {\n                    for (var i = 0; i < reps[0]; ++i) {\n                        for (var j = 0; j < reps[1]; ++j) {\n                            for (var k = 0; k < reps[2]; ++k) {\n                                xGrad = xGrad.add(dy.slice([i * x.shape[0], j * x.shape[1], k * x.shape[2]], [x.shape[0], x.shape[1], x.shape[2]]));\n                            }\n                        }\n                    }\n                } else if (x.rank === 4) {\n                    for (var i = 0; i < reps[0]; ++i) {\n                        for (var j = 0; j < reps[1]; ++j) {\n                            for (var k = 0; k < reps[2]; ++k) {\n                                for (var l = 0; l < reps[3]; ++l) {\n                                    xGrad = xGrad.add(dy.slice([i * x.shape[0], j * x.shape[1], k * x.shape[2], l * x.shape[3]], [x.shape[0], x.shape[1], x.shape[2], x.shape[3]]));\n                                }\n                            }\n                        }\n                    }\n                } else {\n                    throw new Error(\"Gradient for tile operation is not implemented for rank-\" + (x.rank + \" tensors yet.\"));\n                }\n                return xGrad;\n            };\n            return { x: derX };\n        };\n        return _environment.ENV.engine.runKernel(function (backend) {\n            return backend.tile(x, reps);\n        }, { x: x }, grad);\n    };\n    ArrayOps.gather = function (x, indices, axis) {\n        if (axis === void 0) {\n            axis = 0;\n        }\n        util.assertArgumentsAreTensors({ x: x, indices: indices }, 'gather');\n        util.assert(indices.dtype === 'int32', 'Indices must be of dtype `int32`');\n        axis = (0, _axis_util.parseAxisParam)(axis, x.shape)[0];\n        var grad = function (dy) {\n            var derX = function () {\n                return _reduction_ops.ReductionOps.unsortedSegmentSum(dy, indices, x.shape[axis], axis);\n            };\n            return { x: derX };\n        };\n        return _environment.ENV.engine.runKernel(function (backend) {\n            return backend.gather(x, indices, axis);\n        }, { x: x }, grad);\n    };\n    ArrayOps.pad1d = function (x, paddings, constantValue) {\n        if (constantValue === void 0) {\n            constantValue = 0;\n        }\n        util.assert(paddings.length === 2, 'Invalid number of paddings. Must be length of 2.');\n        return ArrayOps.pad(x, [paddings], constantValue);\n    };\n    ArrayOps.pad2d = function (x, paddings, constantValue) {\n        if (constantValue === void 0) {\n            constantValue = 0;\n        }\n        util.assert(paddings.length === 2 && paddings[0].length === 2 && paddings[1].length === 2, 'Invalid number of paddings. Must be length of 2 each.');\n        return ArrayOps.pad(x, paddings, constantValue);\n    };\n    ArrayOps.pad3d = function (x, paddings, constantValue) {\n        if (constantValue === void 0) {\n            constantValue = 0;\n        }\n        util.assert(paddings.length === 3 && paddings[0].length === 2 && paddings[1].length === 2 && paddings[2].length === 2, 'Invalid number of paddings. Must be length of 2 each.');\n        return ArrayOps.pad(x, paddings, constantValue);\n    };\n    ArrayOps.pad4d = function (x, paddings, constantValue) {\n        if (constantValue === void 0) {\n            constantValue = 0;\n        }\n        util.assert(paddings.length === 4 && paddings[0].length === 2 && paddings[1].length === 2 && paddings[2].length === 2 && paddings[3].length === 2, 'Invalid number of paddings. Must be length of 2 each.');\n        return ArrayOps.pad(x, paddings, constantValue);\n    };\n    ArrayOps.pad = function (x, paddings, constantValue) {\n        if (constantValue === void 0) {\n            constantValue = 0;\n        }\n        util.assertArgumentsAreTensors({ x: x }, 'pad');\n        if (x.rank === 0) {\n            throw new Error('pad(scalar) is not defined. Pass non-scalar to pad');\n        }\n        var begin = paddings.map(function (p) {\n            return p[0];\n        });\n        var grad = function (dy) {\n            return { x: function () {\n                    return dy.slice(begin, x.shape);\n                } };\n        };\n        return _environment.ENV.engine.runKernel(function (backend) {\n            return backend.pad(x, paddings, constantValue);\n        }, { x: x }, grad);\n    };\n    ArrayOps.stack = function (tensors, axis) {\n        if (axis === void 0) {\n            axis = 0;\n        }\n        util.assertArgumentsAreTensors({ tensors: tensors }, 'stack');\n        util.assert(tensors.length >= 1, 'Pass at least one tensor to tf.stack');\n        if (tensors.length === 1) {\n            return tensors[0].expandDims(axis);\n        }\n        var rank = tensors[0].rank;\n        var shape = tensors[0].shape;\n        var dtype = tensors[0].dtype;\n        util.assert(axis <= rank, 'Axis must be <= rank of the tensor');\n        tensors.forEach(function (t) {\n            util.assertShapesMatch(shape, t.shape, 'All tensors passed to stack must have matching shapes');\n        });\n        tensors.forEach(function (t) {\n            util.assert(dtype === t.dtype, 'All tensors passed to stack must have matching dtypes');\n        });\n        var expandedTensors = tensors.map(function (t) {\n            return t.expandDims(axis);\n        });\n        return _concat.ConcatOps.concat(expandedTensors, axis);\n    };\n    ArrayOps.unstack = function (value, axis) {\n        if (axis === void 0) {\n            axis = 0;\n        }\n        var num = value.shape[axis];\n        var outputShape = Array(value.rank - 1).fill(0);\n        var outIndex = 0;\n        for (var i = 0; i < value.rank; i++) {\n            if (i !== axis) {\n                outputShape[outIndex] = value.shape[i];\n                outIndex++;\n            }\n        }\n        var splitSizes;\n        splitSizes = Array(num).fill(1);\n        var begin = Array(value.rank).fill(0);\n        var size = value.shape.slice();\n        return splitSizes.map(function (s) {\n            size[axis] = s;\n            var slice = value.slice(begin, size);\n            begin[axis] += s;\n            return slice.reshape(outputShape);\n        });\n    };\n    ArrayOps.split = function (x, numOrSizeSplits, axis) {\n        if (axis === void 0) {\n            axis = 0;\n        }\n        util.assertArgumentsAreTensors({ x: x }, 'split');\n        axis = (0, _axis_util.parseAxisParam)(axis, x.shape)[0];\n        var splitSizes;\n        if (typeof numOrSizeSplits === 'number') {\n            util.assert(x.shape[axis] % numOrSizeSplits === 0, 'Number of splits must evenly divide the axis.');\n            splitSizes = Array(numOrSizeSplits).fill(x.shape[axis] / numOrSizeSplits);\n        } else {\n            util.assert(x.shape[axis] === numOrSizeSplits.reduce(function (a, b) {\n                return a + b;\n            }), 'The sum of sizes must match the size of the axis dimension.');\n            splitSizes = numOrSizeSplits;\n        }\n        var begin = Array(x.rank).fill(0);\n        var size = x.shape.slice();\n        return splitSizes.map(function (s) {\n            size[axis] = s;\n            var slice = x.slice(begin, size);\n            begin[axis] += s;\n            return slice;\n        });\n    };\n    ArrayOps.cumsum = function (x, axis, exclusive, reverse) {\n        if (axis === void 0) {\n            axis = 0;\n        }\n        if (exclusive === void 0) {\n            exclusive = false;\n        }\n        if (reverse === void 0) {\n            reverse = false;\n        }\n        util.assertArgumentsAreTensors({ x: x }, 'cumsum');\n        axis = axis | 0;\n        var permutation = (0, _axis_util.getAxesPermutation)([axis], x.rank);\n        var permutedX = x;\n        if (permutation != null) {\n            permutedX = x.transpose(permutation);\n        }\n        var permutedAxis = (0, _axis_util.getInnerMostAxes)(1, x.rank)[0];\n        var grad = function (dy) {\n            return { permutedX: function () {\n                    return dy.cumsum(axis, exclusive, !reverse);\n                } };\n        };\n        var value = _environment.ENV.engine.runKernel(function (backend) {\n            return backend.cumsum(permutedX, permutedAxis, exclusive, reverse);\n        }, { permutedX: permutedX }, grad);\n        if (permutation != null) {\n            value = value.transpose(permutation);\n        }\n        return value;\n    };\n    ArrayOps.expandDims = function (x, axis) {\n        if (axis === void 0) {\n            axis = 0;\n        }\n        util.assertArgumentsAreTensors({ x: x }, 'expandDims');\n        util.assert(axis <= x.rank, 'Axis must be <= rank of the tensor');\n        var newShape = x.shape.slice();\n        newShape.splice(axis, 0, 1);\n        return ArrayOps.reshape(x, newShape);\n    };\n    ArrayOps.linspace = function (start, stop, num) {\n        if (num === 0) {\n            throw new Error('Cannot request zero samples');\n        }\n        var step = (stop - start) / (num - 1);\n        var values = makeZerosTypedArray(num, 'float32');\n        values[0] = start;\n        for (var i = 1; i < values.length; i++) {\n            values[i] = values[i - 1] + step;\n        }\n        return ArrayOps.tensor1d(values, 'float32');\n    };\n    ArrayOps.range = function (start, stop, step, dtype) {\n        if (step === void 0) {\n            step = 1;\n        }\n        if (dtype === void 0) {\n            dtype = 'float32';\n        }\n        if (step === 0) {\n            throw new Error('Cannot have a step of zero');\n        }\n        var sameStartStop = start === stop;\n        var increasingRangeNegativeStep = start < stop && step < 0;\n        var decreasingRangePositiveStep = stop < start && step > 1;\n        if (sameStartStop || increasingRangeNegativeStep || decreasingRangePositiveStep) {\n            return ArrayOps.zeros([0], dtype);\n        }\n        var numElements = Math.abs(Math.ceil((stop - start) / step));\n        var values = makeZerosTypedArray(numElements, dtype);\n        if (stop < start && step === 1) {\n            step = -1;\n        }\n        values[0] = start;\n        for (var i = 1; i < values.length; i++) {\n            values[i] = values[i - 1] + step;\n        }\n        return ArrayOps.tensor1d(values, dtype);\n    };\n    ArrayOps.buffer = function (shape, dtype, values) {\n        if (dtype === void 0) {\n            dtype = 'float32';\n        }\n        return new _tensor.TensorBuffer(shape, dtype, values);\n    };\n    ArrayOps.print = function (x, verbose) {\n        if (verbose === void 0) {\n            verbose = false;\n        }\n        console.log(tensor_util.tensorToString(x, verbose));\n    };\n    __decorate([(0, _doc.doc)({ heading: 'Tensors', subheading: 'Creation' })], ArrayOps, \"tensor\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Tensors', subheading: 'Creation' })], ArrayOps, \"scalar\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Tensors', subheading: 'Creation' })], ArrayOps, \"tensor1d\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Tensors', subheading: 'Creation' })], ArrayOps, \"tensor2d\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Tensors', subheading: 'Creation' })], ArrayOps, \"tensor3d\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Tensors', subheading: 'Creation' })], ArrayOps, \"tensor4d\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Tensors', subheading: 'Creation' })], ArrayOps, \"tensor5d\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Tensors', subheading: 'Creation' }), _operation.operation], ArrayOps, \"ones\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Tensors', subheading: 'Creation' }), _operation.operation], ArrayOps, \"zeros\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Tensors', subheading: 'Creation' }), _operation.operation], ArrayOps, \"fill\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Tensors', subheading: 'Creation' }), _operation.operation], ArrayOps, \"onesLike\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Tensors', subheading: 'Creation' }), _operation.operation], ArrayOps, \"zerosLike\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Tensors', subheading: 'Creation' }), _operation.operation], ArrayOps, \"clone\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Tensors', subheading: 'Creation' }), _operation.operation], ArrayOps, \"eye\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Tensors', subheading: 'Creation' }), _operation.operation], ArrayOps, \"randomNormal\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Tensors', subheading: 'Creation' }), _operation.operation], ArrayOps, \"truncatedNormal\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Tensors', subheading: 'Creation' }), _operation.operation], ArrayOps, \"randomUniform\", null);\n    __decorate([_operation.operation], ArrayOps, \"rand\", null);\n    __decorate([_operation.operation], ArrayOps, \"multinomial\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Tensors', subheading: 'Creation' }), _operation.operation], ArrayOps, \"oneHot\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Tensors', subheading: 'Creation' }), _operation.operation], ArrayOps, \"fromPixels\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Visualization' })], ArrayOps, \"toPixels\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Tensors', subheading: 'Transformations' }), _operation.operation], ArrayOps, \"reshape\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Tensors', subheading: 'Transformations' })], ArrayOps, \"squeeze\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Tensors', subheading: 'Transformations' }), _operation.operation], ArrayOps, \"cast\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Tensors', subheading: 'Slicing and Joining' }), _operation.operation], ArrayOps, \"tile\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Tensors', subheading: 'Slicing and Joining' }), _operation.operation], ArrayOps, \"gather\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Tensors', subheading: 'Transformations' }), _operation.operation], ArrayOps, \"pad\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Tensors', subheading: 'Slicing and Joining' }), _operation.operation], ArrayOps, \"stack\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Tensors', subheading: 'Slicing and Joining' }), _operation.operation], ArrayOps, \"unstack\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Tensors', subheading: 'Slicing and Joining' }), _operation.operation], ArrayOps, \"split\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Operations', subheading: 'Scan' })], ArrayOps, \"cumsum\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Tensors', subheading: 'Transformations' }), _operation.operation], ArrayOps, \"expandDims\", null);\n    __decorate([_operation.operation, (0, _doc.doc)({ heading: 'Tensors', subheading: 'Creation' })], ArrayOps, \"linspace\", null);\n    __decorate([_operation.operation, (0, _doc.doc)({ heading: 'Tensors', subheading: 'Creation' })], ArrayOps, \"range\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Tensors', subheading: 'Creation' })], ArrayOps, \"buffer\", null);\n    __decorate([(0, _doc.doc)({ heading: 'Tensors', subheading: 'Creation' })], ArrayOps, \"print\", null);\n    return ArrayOps;\n}();\nexports.ArrayOps = ArrayOps;\n\nfunction makeZerosTypedArray(size, dtype) {\n    if (dtype == null || dtype === 'float32') {\n        return new Float32Array(size);\n    } else if (dtype === 'int32') {\n        return new Int32Array(size);\n    } else if (dtype === 'bool') {\n        return new Uint8Array(size);\n    } else {\n        throw new Error(\"Unknown data type $ {dtype}\");\n    }\n}\nfunction makeOnesTypedArray(size, dtype) {\n    var array = makeZerosTypedArray(size, dtype);\n    for (var i = 0; i < array.length; i++) {\n        array[i] = 1;\n    }\n    return array;\n}\nfunction toTypedArray(a, dtype) {\n    if (noConversionNeeded(a, dtype)) {\n        return a;\n    }\n    if (Array.isArray(a)) {\n        a = util.flatten(a);\n    }\n    return util.copyTypedArray(a, dtype);\n}\nfunction noConversionNeeded(a, dtype) {\n    return a instanceof Float32Array && dtype === 'float32' || a instanceof Int32Array && dtype === 'int32' || a instanceof Uint8Array && dtype === 'bool';\n}\n//# sourceMappingURL=array_ops.js.map"},"hash":"26dcc70feaf74d80b9e2513d9be4a5aa","cacheData":{"env":{}}}
{"dependencies":[{"name":"/home/szamulko/Desktop/Projects/PacMan/package.json","includedInParent":true,"mtime":1528724217926},{"name":"/home/szamulko/Desktop/Projects/PacMan/node_modules/@tensorflow/tfjs-layers/package.json","includedInParent":true,"mtime":1528724212618},{"name":"@tensorflow/tfjs-core","loc":{"line":2,"column":148}},{"name":"../common","loc":{"line":3,"column":62}},{"name":"../errors","loc":{"line":4,"column":48}},{"name":"../utils/math_utils","loc":{"line":5,"column":28}},{"name":"../variables","loc":{"line":6,"column":30}},{"name":"./common","loc":{"line":8,"column":32}}],"generated":{"js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n    value: true\n});\nexports.epsilon = undefined;\nexports.disposeScalarCache = disposeScalarCache;\nexports.setBackend = setBackend;\nexports.getBackend = getBackend;\nexports.getScalar = getScalar;\nexports.isBackendSymbolic = isBackendSymbolic;\nexports.shape = shape;\nexports.intShape = intShape;\nexports.dtype = dtype;\nexports.countParams = countParams;\nexports.cast = cast;\nexports.expandDims = expandDims;\nexports.repeat = repeat;\nexports.flatten = flatten;\nexports.batchFlatten = batchFlatten;\nexports.sliceAlongFirstAxis = sliceAlongFirstAxis;\nexports.sliceAlongLastAxis = sliceAlongLastAxis;\nexports.sliceAlongAxis = sliceAlongAxis;\nexports.concatenate = concatenate;\nexports.concatAlongFirstAxis = concatAlongFirstAxis;\nexports.tile = tile;\nexports.identity = identity;\nexports.eyeVariable = eyeVariable;\nexports.scalarTimesArray = scalarTimesArray;\nexports.scalarPlusArray = scalarPlusArray;\nexports.randomNormal = randomNormal;\nexports.dot = dot;\nexports.sign = sign;\nexports.qr = qr;\nexports.oneHot = oneHot;\nexports.gather = gather;\nexports.square = square;\nexports.pow = pow;\nexports.biasAdd = biasAdd;\nexports.elu = elu;\nexports.softsign = softsign;\nexports.dropout = dropout;\nexports.nameScope = nameScope;\nexports.floatx = floatx;\nexports.getUid = getUid;\nexports.hardSigmoid = hardSigmoid;\nexports.inTrainPhase = inTrainPhase;\nexports.gradients = gradients;\n\nvar _tfjsCore = require('@tensorflow/tfjs-core');\n\nvar tfc = _interopRequireWildcard(_tfjsCore);\n\nvar _common = require('../common');\n\nvar _errors = require('../errors');\n\nvar _math_utils = require('../utils/math_utils');\n\nvar math_utils = _interopRequireWildcard(_math_utils);\n\nvar _variables = require('../variables');\n\nvar _common2 = require('./common');\n\nfunction _interopRequireWildcard(obj) { if (obj && obj.__esModule) { return obj; } else { var newObj = {}; if (obj != null) { for (var key in obj) { if (Object.prototype.hasOwnProperty.call(obj, key)) newObj[key] = obj[key]; } } newObj.default = obj; return newObj; } }\n\nvar backend = 'webgl';\nvar DEFAULT_DTYPE = 'float32';\nfunction disposeScalarCache() {\n    for (var typeKey in scalarCache) {\n        for (var key in scalarCache[typeKey]) {\n            scalarCache[typeKey][key].dispose();\n            delete scalarCache[typeKey][key];\n        }\n    }\n}\nfunction setBackend(requestedBackend) {\n    tfc.setBackend(requestedBackend);\n    backend = requestedBackend;\n    disposeScalarCache();\n}\nfunction getBackend() {\n    return backend;\n}\nvar scalarCache = {\n    float32: {},\n    int32: {}\n};\nfunction getScalar(value, dtype) {\n    if (dtype === undefined) {\n        dtype = DEFAULT_DTYPE;\n    }\n    if (scalarCache[dtype][value] == null) {\n        scalarCache[dtype][value] = (0, _tfjsCore.scalar)(value, dtype);\n        tfc.keep(scalarCache[dtype][value]);\n    }\n    return scalarCache[dtype][value];\n}\nvar epsilon = exports.epsilon = _common2.epsilon;\nfunction isBackendSymbolic() {\n    return false;\n}\nfunction shape(x) {\n    return x.shape;\n}\nfunction intShape(x) {\n    return x.shape;\n}\nfunction dtype(x) {\n    return x instanceof _tfjsCore.Tensor ? DEFAULT_DTYPE : x.dtype;\n}\nfunction countParams(x) {\n    var shape = x.shape;\n    if (shape.length > 0) {\n        return shape.reduce(function (a, b) {\n            return a * b;\n        });\n    } else {\n        return 1;\n    }\n}\nfunction cast(x, dtype) {\n    return x.asType(dtype);\n}\nfunction expandDims(x, axis) {\n    if (axis === void 0) {\n        axis = -1;\n    }\n    var outShape = shape(x).slice();\n    if (axis < 0) {\n        axis = outShape.length + axis + 1;\n    }\n    outShape.splice(axis, 0, 1);\n    return x.reshape(outShape);\n}\nfunction repeat(x, n) {\n    return (0, _tfjsCore.tidy)(function () {\n        if (x.shape.length !== 2) {\n            throw new _errors.ValueError(\"repeat() expects a rank-2 tensor, but received a \" + (\"rank-\" + x.shape.length + \" tensor.\"));\n        }\n        var y = expandDims(x, 1);\n        return tile(y, [1, n, 1]);\n    });\n}\nfunction flatten(x) {\n    var newShape = [math_utils.arrayProd(x.shape)];\n    return x.reshape(newShape);\n}\nfunction batchFlatten(x) {\n    if (x.rank <= 1) {\n        throw new _errors.ValueError(\"batchFlatten requires a minimum rank of 2. Got rank: \" + x.rank + \".\");\n    }\n    var newShape = [x.shape[0], math_utils.arrayProd(x.shape, 1)];\n    return x.reshape(newShape);\n}\nfunction sliceAlongFirstAxis(array, start, size) {\n    return (0, _tfjsCore.tidy)(function () {\n        switch (array.rank) {\n            case 1:\n                return tfc.slice1d(array, start, size);\n            case 2:\n                return tfc.slice2d(array, [start, 0], [size, array.shape[1]]);\n            case 3:\n                return tfc.slice3d(array, [start, 0, 0], [size, array.shape[1], array.shape[2]]);\n            case 4:\n                return tfc.slice4d(array, [start, 0, 0, 0], [size, array.shape[1], array.shape[2], array.shape[3]]);\n            default:\n                throw new _errors.ValueError(\"sliceAlongFirstAxis() received an unsupported tensor rank: \" + (\"\" + array.rank));\n        }\n    });\n}\nfunction sliceAlongLastAxis(array, start, size) {\n    return (0, _tfjsCore.tidy)(function () {\n        switch (array.rank) {\n            case 1:\n                return tfc.slice1d(array, start, size);\n            case 2:\n                return tfc.slice2d(array, [0, start], [array.shape[0], size]);\n            case 3:\n                return tfc.slice3d(array, [0, 0, start], [array.shape[0], array.shape[1], size]);\n            case 4:\n                return tfc.slice4d(array, [0, 0, 0, start], [array.shape[0], array.shape[1], array.shape[2], size]);\n            default:\n                throw new _errors.ValueError(\"sliceAlongLastAxis() received an unsupported tensor rank: \" + (\"\" + array.rank));\n        }\n    });\n}\nfunction sliceAlongAxis(array, start, size, axis) {\n    return (0, _tfjsCore.tidy)(function () {\n        switch (array.rank) {\n            case 1:\n                return tfc.slice1d(array, start, size);\n            case 2:\n                switch (axis) {\n                    case 1:\n                        return sliceAlongFirstAxis(array, start, size);\n                    case 2:\n                        return sliceAlongLastAxis(array, start, size);\n                    default:\n                        throw new _errors.ValueError(\"The axis is not within the rank of the tensor \" + (\"\" + axis));\n                }\n            case 3:\n                switch (axis) {\n                    case 1:\n                        return sliceAlongFirstAxis(array, start, size);\n                    case 2:\n                        return tfc.slice3d(array, [0, start, 0], [array.shape[0], size, array.shape[2]]);\n                    case 3:\n                        return sliceAlongLastAxis(array, start, size);\n                    default:\n                        throw new _errors.ValueError(\"The axis is not within the rank of the tensor \" + (\"\" + axis));\n                }\n            case 4:\n                switch (axis) {\n                    case 1:\n                        return sliceAlongFirstAxis(array, start, size);\n                    case 2:\n                        return tfc.slice4d(array, [0, start, 0, 0], [array.shape[0], size, array.shape[2], array.shape[3]]);\n                    case 3:\n                        return tfc.slice4d(array, [0, 0, start, 0], [array.shape[0], array.shape[1], size, array.shape[3]]);\n                    case 4:\n                        return sliceAlongLastAxis(array, start, size);\n                    default:\n                        throw new _errors.ValueError(\"The axis is not within the rank of the tensor \" + (\"\" + axis));\n                }\n            default:\n                throw new _errors.ValueError(\"sliceAlongLastAxis() received an unsupported tensor rank: \" + (\"\" + array.rank));\n        }\n    });\n}\nfunction concatenate(tensors, axis) {\n    if (axis === void 0) {\n        axis = -1;\n    }\n    var rank;\n    if (axis < 0) {\n        rank = tensors[0].rank;\n        if (rank !== 0) {\n            axis = rank;\n        } else {\n            axis = 0;\n        }\n    }\n    if (axis === tensors[0].rank) {\n        axis = -1;\n    }\n    return tfc.concat(tensors, axis);\n}\nfunction concatAlongFirstAxis(a, b) {\n    switch (a.rank) {\n        case 1:\n            return tfc.concat1d([a, b]);\n        case 2:\n            return tfc.concat2d([a, b], 0);\n        case 3:\n            return tfc.concat3d([a, b], 0);\n        case 4:\n            return tfc.concat4d([a, b], 0);\n        default:\n            throw new _errors.ValueError('concatAlongFirstAxis() received an unsupported tensor rank: ' + a.rank);\n    }\n}\nfunction tile(x, n) {\n    if (!Array.isArray(n)) {\n        n = [n];\n    }\n    if (x.rank !== n.length) {\n        throw new _errors.ValueError(\"The length of input n (\" + n.length + \") does not match \" + (\"the number of dimensions in input x (\" + x.rank + \")\"));\n    }\n    return tfc.tile(x, n);\n}\nfunction identity(x) {\n    return x.clone();\n}\nfunction eyeVariable(size, dtype, name) {\n    return new _variables.LayerVariable(tfc.eye(size, size, null, dtype), dtype, name);\n}\nfunction scalarTimesArray(c, x) {\n    return tfc.mul(c, x);\n}\nfunction scalarPlusArray(c, x) {\n    return tfc.add(c, x);\n}\nfunction randomNormal(shape, mean, stddev, dtype, seed) {\n    if (mean === void 0) {\n        mean = 0.0;\n    }\n    if (stddev === void 0) {\n        stddev = 1.0;\n    }\n    return tfc.randomNormal(shape, mean, stddev, dtype, seed);\n}\nfunction dot(x, y) {\n    if (y.rank !== 2) {\n        throw new _errors.NotImplementedError(\"dot support for y other than rank 2 is not yet implemented: \" + (\"y shape = \" + shape));\n    } else {\n        if (x.rank === 2) {\n            return tfc.matMul(x, y);\n        } else if (x.rank === 3) {\n            var xShape0 = x.shape[0];\n            var xShape1 = x.shape[1];\n            var xShape2 = x.shape[2];\n            x = x.reshape([xShape0 * xShape1, xShape2]);\n            return tfc.matMul(x, y).reshape([xShape0, xShape1, y.shape[1]]);\n        } else {\n            throw new _errors.NotImplementedError(\"dot support for x of rank \" + x.rank + \" is not yet implemented: \" + (\"x shape = \" + shape));\n        }\n    }\n}\nfunction sign(x) {\n    return (0, _tfjsCore.tidy)(function () {\n        var zerosLikeX = (0, _tfjsCore.zerosLike)(x);\n        var onesLikeX = (0, _tfjsCore.onesLike)(x);\n        return (0, _tfjsCore.where)(tfc.equal(x, zerosLikeX), zerosLikeX, (0, _tfjsCore.where)(tfc.greater(x, (0, _tfjsCore.zerosLike)(x)), onesLikeX, scalarTimesArray(getScalar(-1), onesLikeX)));\n    });\n}\nfunction qr(x) {\n    var _a = (0, _tfjsCore.tidy)(function () {\n        if (x.shape.length !== 2) {\n            throw new _errors.ValueError(\"qr() requires a 2D Tensor, but got a \" + x.shape.length + \"D Tensor.\");\n        }\n        if (x.shape[0] < x.shape[1]) {\n            throw new _errors.ValueError(\"qr() requires x.shape[0] >= x.shape[1], but got shape: [\" + x.shape + \"]\");\n        }\n        var m = x.shape[0];\n        var n = x.shape[1];\n        var q = tfc.eye(m);\n        var r = x.clone();\n        var one2D = (0, _tfjsCore.tensor2d)([[1]], [1, 1]);\n        var w = one2D.clone();\n        var _loop_1 = function (j) {\n            var rTemp = r;\n            var wTemp = w;\n            var qTemp = q;\n            _a = (0, _tfjsCore.tidy)(function () {\n                var rjEnd1 = r.slice([j, j], [m - j, 1]);\n                var normX = tfc.norm(rjEnd1);\n                var rjj = r.slice([j, j], [1, 1]);\n                var s = tfc.neg(sign(rjj));\n                var u1 = rjj.sub(tfc.mul(s, normX));\n                var wPre = tfc.div(rjEnd1, u1);\n                if (wPre.shape[0] === 1) {\n                    w = one2D.clone();\n                } else {\n                    w = one2D.concat(wPre.slice([1, 0], [wPre.shape[0] - 1, wPre.shape[1]]), 0);\n                }\n                var tau = tfc.neg(tfc.div(tfc.matMul(s, u1), normX));\n                var rjEndAll = r.slice([j, 0], [m - j, n]);\n                var tauTimesW = tau.mul(w);\n                if (j === 0) {\n                    r = rjEndAll.sub(tauTimesW.matMul(w.transpose().matMul(rjEndAll)));\n                } else {\n                    r = r.slice([0, 0], [j, n]).concat(rjEndAll.sub(tauTimesW.matMul(w.transpose().matMul(rjEndAll))), 0);\n                }\n                var qAllJEnd = q.slice([0, j], [m, q.shape[1] - j]);\n                if (j === 0) {\n                    q = qAllJEnd.sub(qAllJEnd.matMul(w).matMul(tauTimesW.transpose()));\n                } else {\n                    q = q.slice([0, 0], [m, j]).concat(qAllJEnd.sub(qAllJEnd.matMul(w).matMul(tauTimesW.transpose())), 1);\n                }\n                return [w, r, q];\n            }), w = _a[0], r = _a[1], q = _a[2];\n            (0, _tfjsCore.dispose)([rTemp, wTemp, qTemp]);\n            var _a;\n        };\n        for (var j = 0; j < n; ++j) {\n            _loop_1(j);\n        }\n        return [q, r];\n    }),\n        qOuter = _a[0],\n        rOuter = _a[1];\n    return [qOuter, rOuter];\n}\nfunction oneHot(indices, numClasses) {\n    return (0, _tfjsCore.tidy)(function () {\n        if (indices.rank !== 1) {\n            throw new Error('Only 1D one-hot tensors are supported in the ' + 'deeplearn backend, at present.');\n        }\n        indices = indices.toInt();\n        return tfc.oneHot(indices, numClasses).toFloat();\n    });\n}\nfunction gather(reference, indices, axis) {\n    return (0, _tfjsCore.tidy)(function () {\n        if (Array.isArray(indices)) {\n            indices = (0, _tfjsCore.tensor1d)(indices, 'int32');\n        } else {\n            indices = indices.toInt();\n        }\n        return tfc.gather(reference, indices, axis);\n    });\n}\nfunction square(x) {\n    return tfc.mulStrict(x, x);\n}\nfunction pow(x, a) {\n    return (0, _tfjsCore.tidy)(function () {\n        if (typeof a === 'number') {\n            a = (0, _tfjsCore.scalar)(Math.round(a), 'int32');\n        }\n        if (a.dtype !== 'int32') {\n            throw new _errors.NotImplementedError(\"Non-int32 dtype (\" + a.dtype + \") is not supported by pow() yet\");\n        }\n        return tfc.pow(x, a);\n    });\n}\nfunction biasAdd(x, bias, dataFormat) {\n    return (0, _tfjsCore.tidy)(function () {\n        if (dataFormat == null) {\n            dataFormat = (0, _common2.imageDataFormat)();\n        }\n        (0, _common.checkDataFormat)(dataFormat);\n        if (bias.rank !== 1 && bias.rank !== x.rank) {\n            throw new _errors.ValueError('Unexpected bias dimensions: ' + bias.rank + '; expected it to be 1 or ' + x.rank);\n        }\n        var biasShape = bias.shape;\n        var y;\n        if (x.rank === 5) {\n            if (dataFormat === 'channelsFirst') {\n                if (biasShape.length === 1) {\n                    y = x.add(bias.reshape([1, biasShape[0], 1, 1, 1]));\n                } else {\n                    y = x.add(bias.reshape([1, biasShape[3], biasShape[0], biasShape[1], biasShape[2]]));\n                }\n            } else if (dataFormat === 'channelsLast') {\n                if (biasShape.length === 1) {\n                    y = x.add(bias.reshape([1, 1, 1, 1, biasShape[0]]));\n                } else {\n                    y = x.add(bias.reshape([1].concat(biasShape)));\n                }\n            }\n        } else if (x.rank === 4) {\n            if (dataFormat === 'channelsFirst') {\n                if (biasShape.length === 1) {\n                    y = x.add(bias.reshape([1, biasShape[0], 1, 1]));\n                } else {\n                    y = x.add(bias.reshape([1, biasShape[2], biasShape[0], biasShape[1]]));\n                }\n            } else if (dataFormat === 'channelsLast') {\n                if (biasShape.length === 1) {\n                    y = x.add(bias.reshape([1, 1, 1, biasShape[0]]));\n                } else {\n                    y = x.add(bias.reshape([1].concat(biasShape)));\n                }\n            }\n        } else if (x.rank === 3) {\n            if (dataFormat === 'channelsFirst') {\n                if (biasShape.length === 1) {\n                    y = x.add(bias.reshape([1, biasShape[0], 1]));\n                } else {\n                    y = x.add(bias.reshape([1, biasShape[1], biasShape[0]]));\n                }\n            } else if (dataFormat === 'channelsLast') {\n                if (biasShape.length === 1) {\n                    y = x.add(bias.reshape([1, 1, biasShape[0]]));\n                } else {\n                    y = x.add(bias.reshape([1].concat(biasShape)));\n                }\n            }\n        } else if (x.rank < 3) {\n            y = x.add(bias);\n        } else {\n            throw new _errors.ValueError(\"Unsupported input rank by biasAdd: \" + x.rank);\n        }\n        return y;\n    });\n}\nfunction elu(x, alpha) {\n    if (alpha === void 0) {\n        alpha = 1;\n    }\n    if (alpha !== 1) {\n        throw new _errors.NotImplementedError(\"Support for alpha values other than 1 (\" + alpha + \") is not implemented \" + \"yet.\");\n    }\n    return tfc.elu(x);\n}\nfunction softsign(x) {\n    return (0, _tfjsCore.tidy)(function () {\n        return tfc.div(x, tfc.add(getScalar(1), tfc.abs(x)));\n    });\n}\nfunction dropout(x, level, noiseShape, seed) {\n    return (0, _tfjsCore.tidy)(function () {\n        if (noiseShape != null && !_tfjsCore.util.arraysEqual(x.shape, noiseShape)) {\n            throw new _errors.NotImplementedError('Non-default noise shape is not implemented yet: ' + JSON.stringify(noiseShape));\n        }\n        if (seed != null) {\n            throw new _errors.NotImplementedError('seed is not implemented for dropout yet.');\n        }\n        var multiplier = tfc.step(tfc.add(tfc.neg(level), tfc.randomUniform(x.shape, 0, 1, 'float32')));\n        multiplier = tfc.mul(tfc.div(getScalar(1), tfc.sub(getScalar(1), level)), multiplier);\n        return tfc.mul(x, multiplier);\n    });\n}\nfunction nameScope(name, fn) {\n    return (0, _common.nameScope)(name, fn);\n}\nfunction floatx() {\n    return 'float32';\n}\nvar _uidPrefixes = {};\nfunction getUid(prefix) {\n    if (prefix === void 0) {\n        prefix = '';\n    }\n    if (!(prefix in _uidPrefixes)) {\n        _uidPrefixes[prefix] = 0;\n    }\n    _uidPrefixes[prefix] += 1;\n    return prefix + _uidPrefixes[prefix].toString();\n}\nfunction hardSigmoid(x) {\n    return (0, _tfjsCore.tidy)(function () {\n        var y = scalarPlusArray(getScalar(0.5), scalarTimesArray(getScalar(0.2), x));\n        return tfc.clipByValue(y, 0, 1);\n    });\n}\nfunction inTrainPhase(x, alt, training) {\n    if (training === void 0) {\n        training = false;\n    }\n    return training ? x() : alt();\n}\nfunction gradients(lossFn, variables) {\n    var variableList = variables.map(function (variable) {\n        return variable.read();\n    });\n    var valudAndGrads = (0, _tfjsCore.variableGrads)(lossFn, variableList);\n    return variables.map(function (variable) {\n        return valudAndGrads.grads[variable.name];\n    });\n}\n//# sourceMappingURL=tfjs_backend.js.map"},"hash":"ab38d46602c3385ffa9c609e8e827844","cacheData":{"env":{}}}